{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6468e6d6-b501-44f9-b459-56787cf6ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 1. import pacakge\"\"\"\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_process_YW import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97b52c26-b1c0-44ba-beca-68e42d0aba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 2. set up hyper-parameters\"\"\"\n",
    "Batch_size = 1\n",
    "numWorkers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dca42f7-2967-443b-b636-9bc7ff080669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 3. set up device\"\"\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f87c19-dda8-49b4-a403-380fd0f4659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processing...\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 4. load data\"\"\"\n",
    "trainloader, testloader = load_data(Batch_size, numWorkers)\n",
    "# training set 1000, test set 500\n",
    "# shape of single image: torch.Size([1, 3, 32, 32])\n",
    "# shape of single label: torch.Size([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9accc02b-60f6-4b64-b05b-308ff8f620b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 5. define model, loss function, optimizer\"\"\"\n",
    "\"\"\"5.1 agent model\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LocalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(3 * 32 * 32, 120)\n",
    "        self.fc2 = nn.Linear(3 * 32 * 32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3 * 32 * 32)\n",
    "        #print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# mobile_net = LocalNet()\n",
    "mobile_net = LocalNet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23e08660-4543-4325-a896-d7ba8926b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.SGD(mobile_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "916c527a-92a4-417f-85af-20e8287f5eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1, 1])) must be the same as input size (torch.Size([64, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 24\u001b[0m\n\u001b[1;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m mobile_net(inputs)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# outputs = (outputs+1)/2\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(labels)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(outputs)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/Learning_with_reject/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Learning_with_reject/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Learning_with_reject/lib/python3.10/site-packages/torch/nn/modules/loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Learning_with_reject/lib/python3.10/site-packages/torch/nn/functional.py:3193\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3190\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1, 1])) must be the same as input size (torch.Size([64, 1]))"
     ]
    }
   ],
   "source": [
    "\"\"\"5.1.2 train agent model\"\"\"\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        print(inputs.shape)\n",
    "        print(labels)\n",
    "\n",
    "        # labels=labels*2-1\n",
    "        labels = torch.reshape(labels, (Batch_size, 1))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = mobile_net(inputs)\n",
    "        # outputs = (outputs+1)/2\n",
    "\n",
    "        # print(labels)\n",
    "        # print(outputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './localnet.pth'\n",
    "torch.save(mobile_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656b2d35-fb4b-4f86-aee6-7b50bcd035de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 500 test images: 51 %\n",
      "Total sample size: 400\n",
      "correct 1: 101\n",
      "correct 0: 106\n"
     ]
    }
   ],
   "source": [
    "\"\"\"5.1.3 test agent model\"\"\"\n",
    "mobile_net = LocalNet().to(device)\n",
    "mobile_net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "correct_1=0\n",
    "correct_0=0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        #images, labels = data\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        outputs = mobile_net(images)\n",
    "        #_, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = [1 if x > 0 else 0 for x in outputs]\n",
    "        predicted=torch.tensor(predicted).to(device)\n",
    "        #print(type(predicted))\n",
    "        #print(type(labels))\n",
    "        total += labels.size(0)\n",
    "        correct_1 += (predicted == labels and labels==1).sum().item()\n",
    "        correct_0+=(predicted == labels and labels==0).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 500 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print('Total sample size: %d' %total)\n",
    "print('correct 1: %d'%correct_1)\n",
    "print('correct 0: %d'%correct_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d100da5-ea12-4275-ba3e-f9ee14d5e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"5.2 consultant model\"\"\"\n",
    "c1=1\n",
    "ce=0\n",
    "\n",
    "class EdgeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EdgeNet, self).__init__()\n",
    "        \n",
    "        #rejector\n",
    "        self.rj1=  nn.Linear(3 * 32 * 32, 120)\n",
    "        self.rj2=  nn.Linear(120, 1)\n",
    "        \n",
    "        #edge classifier\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # reject\n",
    "        y = x.view(-1, 3 * 32 * 32)\n",
    "        y = F.relu(self.rj1(y))\n",
    "        y = self.sigmoid(self.rj2(y))*2-1\n",
    "        #print(y)\n",
    "        #m=fixed_mobile_net(x)\n",
    "        \n",
    "        #edge classifier\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))*2-1\n",
    "        #print(x)\n",
    "    \n",
    "        return [y,x]\n",
    "\n",
    "# edge_net = EdgeNet()\n",
    "edge_net = EdgeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298feff-d674-475a-99ae-f3b3d425040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#custom loss function\n",
    "def surrogate_loss(outputs, labels, mobile_outputs):\n",
    "    # here labels={-1. +1}, so we have to pre-processing before input labels\n",
    "    r,e=outputs[0],outputs[1]\n",
    "    #print(r,e)\n",
    "    #value, predicted = torch.max(mobile_outputs.data, 1)\n",
    "    mobil_predicted = [1 if x > 0 else -1 for x in mobile_outputs] #m={-1, +1}\n",
    "    mobil_predicted=torch.tensor(mobil_predicted).to(device)\n",
    "    \n",
    "    #we assume P(m!=Y|X=x)=0.3 in this case\n",
    "    value =0.28  # assume that the error rate for each input x is constant.\n",
    "    beta = 2\n",
    "    #alpha=beta*(0+math.sqrt((1-value)-(1-value)*(1-value)))/(1-value)\n",
    "    alpha=2*(math.sqrt(value-value*value))/(value)\n",
    "    #alpha=beta*(ce+math.sqrt(4*c1*(value-ce)-4*value*value+8*ce*value-4*ce*ce)/(2*value)\n",
    "    #print(alpha)\n",
    "    if mobil_predicted==labels:\n",
    "        loss=torch.exp(-r-labels*e)\n",
    "        #print(loss)\n",
    "\n",
    "    else:\n",
    "        loss=torch.exp(alpha*r)+torch.exp(-r-labels*e)\n",
    "    return loss\n",
    "\n",
    "#criterion=surrogate_loss\n",
    "optimizer = optim.SGD(edge_net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559ca1d-cdd4-4ca0-8662-f0b17b6f066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "for epoch in range(10):  # loop over the dataset multiple times [2, 5, 10]\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        #inputs, labels = data\n",
    "        inputs, labels = data[0].to(device),data[1].to(device)\n",
    "        labels=labels*2-1\n",
    "        labels=torch.reshape(labels, (Batch_size, 1)).to(device) #this part is ok \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = edge_net(inputs)\n",
    "        #print(outputs[0],outputs[1])\n",
    "        #something wrong happened here.\n",
    "        \n",
    "        \n",
    "        mobile_outputs=mobile_net(inputs) #this part is ok\n",
    "        #print(mobile_outputs.item())\n",
    "        #mobile_outputs.requires_grad_(False)\n",
    "        loss = surrogate_loss(outputs, labels, mobile_outputs.detach()).to(device)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        #break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36edebc0-43ef-462f-8a12-954270a1c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predict_locally=0\n",
    "predict_remotely=0\n",
    "with torch.no_grad(): # what does it mean?\n",
    "    for data in testloader:\n",
    "        #images, labels = data\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        edge_outputs = edge_net(images)\n",
    "        mobile_outputs = mobile_net(images)\n",
    "        r, e=edge_outputs[0].to(device),edge_outputs[1].to(device)\n",
    "        #print(mobile_outputs)\n",
    "        #print(r)\n",
    "        #print(e)\n",
    "        \n",
    "        #if r*2-1>0: #assume that interval of r is [0,1]\n",
    "        if r>0:\n",
    "            # predict locally\n",
    "            predict_locally+=1\n",
    "            predicted = [1 if x > 0 else 0 for x in mobile_outputs]\n",
    "            predicted=torch.tensor(predicted).to(device)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        else:\n",
    "            predict_remotely+=1\n",
    "            predicted = [1 if x > 0 else 0 for x in e]\n",
    "            predicted=torch.tensor(predicted).to(device)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()            \n",
    "\n",
    "print(\"Decision made locally:%d\" %predict_locally)\n",
    "print(\"Decision made on edge:%d\" %predict_remotely)\n",
    "print('Accuracy of the network on the 2000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42e5a6-0b6e-416f-bb5b-1e8ade149f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run the edge:\n",
    "correct = 0\n",
    "total = 0\n",
    "predict_locally=0\n",
    "predict_remotely=0\n",
    "correct_1=0\n",
    "correct_0=0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        #images, labels = data\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        edge_outputs = edge_net(images)\n",
    "        mobile_outputs = mobile_net(images).to(device)\n",
    "        r, e=edge_outputs[0].to(device),edge_outputs[1].to(device)\n",
    "        #print(mobile_outputs)\n",
    "        #print(r)\n",
    "        #print(e)\n",
    "\n",
    "        predict_remotely+=1\n",
    "        #print(e)\n",
    "        predicted = [1 if x > 0 else 0 for x in e]\n",
    "        predicted=torch.tensor(predicted).to(device)\n",
    "        #print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct_1 += (predicted == labels and labels==1).sum().item()\n",
    "        correct_0+=(predicted == labels and labels==0).sum().item()\n",
    "        correct += (predicted == labels).sum().item()            \n",
    "\n",
    "print(predict_locally)\n",
    "print(predict_remotely)\n",
    "print('Accuracy of the network on the 2000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print('Total sample size: %d' %total)\n",
    "print('correct 1: %d'%correct_1)\n",
    "print('correct 0: %d'%correct_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5390e88-4286-491e-b485-1b92bdd616ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobile and edge work together,\n",
    "# there is unbalance happen to rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55ddbe-55ed-4f06-9659-5b0ba87e9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predict_locally=0\n",
    "predict_remotely=0\n",
    "local_1=0\n",
    "local_0=0\n",
    "edge_1=0\n",
    "edge_0=0\n",
    "\n",
    "local_correct_1=0\n",
    "local_correct_0=0\n",
    "edge_correct_0=0\n",
    "edge_correct_1=0\n",
    "local_correct_edgeSample_0=0\n",
    "local_correct_edgeSample_1=0\n",
    "edge_correct_mobilesample_0=0\n",
    "edge_correct_mobilesample_1=0\n",
    "mobile_equal_edge_locally_0=0\n",
    "mobile_equal_edge_remotely_0=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        #images, labels = data\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        edge_outputs = edge_net(images)\n",
    "        mobile_outputs = mobile_net(images)\n",
    "        r, e=edge_outputs[0].to(device),edge_outputs[1].to(device)\n",
    "        #print(mobile_outputs)\n",
    "        #print(r)\n",
    "        #print(e)\n",
    "        \n",
    "        #if r*2-1>0: #assume that interval of r is [0,1]\n",
    "        if r>0:\n",
    "            # predict locally\n",
    "            predict_locally+=1\n",
    "            predicted = [1 if x > 0 else 0 for x in mobile_outputs]\n",
    "            predicted=torch.tensor(predicted).to(device)\n",
    "            edge_predicted= [1 if x > 0 else 0 for x in e]\n",
    "            edge_predicted=torch.tensor(edge_predicted).to(device)\n",
    "            total += labels.size(0)\n",
    "            local_1+= (labels==1).sum().item()\n",
    "            local_0+=(labels==0).sum().item()\n",
    "            local_correct_0+=(predicted == labels and labels==0).sum().item()\n",
    "            edge_correct_mobilesample_0+=(edge_predicted == labels and labels==0).sum().item()\n",
    "            local_correct_1+=(predicted == labels and labels==1).sum().item()\n",
    "            edge_correct_mobilesample_1+=(edge_predicted == labels and labels==1).sum().item()\n",
    "            mobile_equal_edge_locally_0+=(predicted == labels and labels==0 and edge_predicted== labels).sum().item()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        else:\n",
    "            predict_remotely+=1\n",
    "            predicted = [1 if x > 0 else 0 for x in e]\n",
    "            local_predicted=[1 if x > 0 else 0 for x in mobile_outputs]\n",
    "            local_predicted=torch.tensor(local_predicted).to(device)\n",
    "            predicted=torch.tensor(predicted).to(device)\n",
    "            total += labels.size(0)\n",
    "            edge_0+=(labels==0).sum().item()\n",
    "            edge_1+=(labels==1).sum().item()\n",
    "            edge_correct_0+=(predicted == labels and labels==0).sum().item()\n",
    "            local_correct_edgeSample_0+=(local_predicted == labels and labels==0).sum().item()\n",
    "            mobile_equal_edge_remotely_0+=(local_predicted == labels and labels==0 and predicted == labels).sum().item()\n",
    "            \n",
    "            edge_correct_1+=(predicted == labels and labels==1).sum().item()\n",
    "            local_correct_edgeSample_1+=(local_predicted == labels and labels==1).sum().item()\n",
    "            correct += (predicted == labels).sum().item()            \n",
    "\n",
    "print(\"Decision made locally:%d\" %predict_locally)\n",
    "print(\"local true 1: %d, accuracy: %d %%, accuracy for edge classifier on those samples %d %%\"%(local_1, 100*local_correct_1/local_1,100*edge_correct_mobilesample_1/local_1))\n",
    "print(\"local true 0: %d, accuracy: %d %%, accuracy for edge classifier on those samples %d %%\"%(local_0, 100*local_correct_0/local_0,100*edge_correct_mobilesample_0/local_0))\n",
    "print(\"edge = mobile =0 locally: %d\"%(mobile_equal_edge_locally_0))\n",
    "print(\"Decision made on edge:%d\" %predict_remotely)\n",
    "print(\"edge true 1: %d, accuracy:%d %%, accuracy for mobile classifier on those samples %d %%\"%(edge_1, 100*edge_correct_1/edge_1, 100*local_correct_edgeSample_1/edge_1))\n",
    "print(\"edge true 0: %d, accuracy:%d %%, accuracy for mobile classifier on those samples %d %%\"%(edge_0, 100*edge_correct_0/edge_0,100*local_correct_edgeSample_0/edge_0 ))\n",
    "print(\"edge = mobile =0 remotely: %d\"%(mobile_equal_edge_remotely_0))\n",
    "print('Accuracy of the network on the 2000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
